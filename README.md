# GPT-2 Чат-бот

Веб-чат-бот на основі моделі GPT-2 від OpenAI з підтримкою історії діалогів.

## Особливості

- Використання моделі GPT-2 через Transformers
- Веб-інтерфейс на Flask
- Збереження історії діалогів у JSON
- Контекстна генерація відповідей
- Налаштування параметрів моделі в реальному часі
- Автоматичне визначення GPU/CPU

## Встановлення

1. Клонуйте репозиторій або перейдіть до директорії проекту

2. Створіть віртуальне середовище:
```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
venv\Scripts\activate     # Windows
```

3. Встановіть залежності:
```bash
pip install -r requirements.txt
```

4. Запустіть сервер:
```bash
python app.py
```

5. Відкрийте браузер: http://localhost:5000

## Структура проекту

```
gpt2chat/
├── app.py                      # Головний Flask додаток
├── config.py                   # Конфігурація
├── requirements.txt            # Залежності
├── models/                     # ML модель
│   ├── __init__.py
│   └── gpt2_model.py          # GPT-2 реалізація
├── services/                   # Бізнес-логіка
│   ├── __init__.py
│   ├── chat_service.py        # Логіка чату
│   └── storage_service.py     # Збереження даних
├── api/                        # API endpoints
│   ├── __init__.py
│   └── routes.py              # Flask routes
├── static/                     # Статичні файли
│   ├── css/style.css          # Стилі
│   └── js/chat.js             # JavaScript
├── templates/                  # HTML шаблони
│   └── index.html             # Головна сторінка
├── data/                       # Збережені діалоги
│   └── conversations/         # JSON файли
└── utils/                      # Допоміжні функції
    ├── __init__.py
    └── text_utils.py
```

## Налаштування

Параметри можна змінити в `config.py`:

- `MODEL_NAME` - назва моделі (за замовчуванням: openai-community/gpt2)
- `TEMPERATURE` - креативність (0.1-1.0, за замовчуванням: 0.7)
- `MAX_LENGTH` - довжина генерації (за замовчуванням: 100)
- `MAX_HISTORY_MESSAGES` - кількість повідомлень в контексті (за замовчуванням: 10)
- `MAX_CONTEXT_TOKENS` - максимум токенів контексту (за замовчуванням: 512)

## API Endpoints

- `POST /api/conversations` - Створити новий діалог
- `POST /api/conversations/<id>/messages` - Відправити повідомлення
- `GET /api/conversations/<id>/messages` - Отримати історію
- `GET /api/conversations` - Список всіх діалогів
- `DELETE /api/conversations/<id>` - Видалити діалог
- `GET /api/health` - Перевірка стану системи

## Використання

1. При запуску автоматично створюється новий діалог
2. Введіть повідомлення в текстове поле
3. Натисніть "Відправити" або Enter для відправки
4. Модель згенерує відповідь на основі історії діалогу
5. Використовуйте sliders для зміни параметрів генерації
6. Натисніть "Новий чат" для створення нової розмови

## Технічні деталі

### Форматування діалогу для GPT-2

Модель використовує формат:
```
User: [повідомлення користувача]
Assistant: [відповідь асистента]
User: [наступне повідомлення]
Assistant:
```

### Управління контекстом

- Максимум 1024 токени для GPT-2
- Резервуємо 512 токенів для промпту, 512 для генерації
- Старі повідомлення автоматично видаляються при перевищенні ліміту

### Параметри генерації

- **temperature** (0.7) - баланс між креативністю та когерентністю
- **top_k** (50) - розглядаємо top-50 найімовірніших токенів
- **top_p** (0.9) - nucleus sampling для якісного тексту
- **repetition_penalty** (1.2) - зменшує повторення слів

## Вимоги

- Python 3.8+
- PyTorch 2.1.2
- Transformers 4.36.2
- Flask 3.0.0
- ~500MB для моделі GPT-2

## Можливі проблеми та рішення

### Помилка завантаження моделі
- Переконайтеся що у вас є інтернет-з'єднання
- Модель завантажиться автоматично з HuggingFace при першому запуску

### Повільна генерація
- На CPU генерація може займати 5-10 секунд
- Для прискорення використовуйте GPU з CUDA

### Помилка пам'яті
- Зменшіть MAX_CONTEXT_TOKENS в config.py
- Зменшіть MAX_LENGTH для генерації

## Ліцензія

MIT

## Автор

Створено з використанням Claude Code
